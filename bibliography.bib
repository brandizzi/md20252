
@article{watada_emerging_2019,
	title = {Emerging {Trends}, {Techniques} and {Open} {Issues} of {Containerization}: {A} {Review}},
	volume = {7},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Emerging {Trends}, {Techniques} and {Open} {Issues} of {Containerization}},
	url = {https://ieeexplore.ieee.org/document/8861307/},
	doi = {10.1109/ACCESS.2019.2945930},
	abstract = {Containerization is revolutionizing the way that many industries operate, provisioning major impact to modern computing technologies because it is extra lightweight, highly portable, energy, resource and storage efﬁcient, cost-effective, performance efﬁcient, and extremely quick during boot up. These often facilitate efﬁcient load balancing, low-level system maintenance, server consolidation (for efﬁcient energy and resource utilization) and replication of instances over geographical locations for better fault tolerance to escalate application reliability. However, some recent literature have addressed various challenges (such as complex networking, persistent storage facilities, cross data centers and multicloud supports, security issues, and lack of available, capable container management APIs, etc.) regarding successful container adoption in industries, which might have resulted in a seemingly meager increase in industrial deployments of containerization over the past few years despite bestowing efﬁcient lightweight virtualization. Moreover, a comprehensive overview of containerizations along with their popularity dynamics has still not been found in contemporary literature, which further extends knowledge gap between developers and available technologies. Hence, current study touches upon different technicalities involved in containerization with potential problems and possible solutions along with various important industrial applications to manifest its existing supports and technical hardships. Finally, we have conducted a comprehensive experimental study to compare the performance of VMs, containers and unikernels in terms of CPU utilization, memory footprints, network bandwidth, execution time and technological maturity using standard benchmarks and observed containers to deliver satisfactory performance in almost all aspects, however, are still not free from issues regarding isolation \& security, performance stability, lack of available efﬁcient tools for crossplatform support and persistent storage. Unikernels deliver good performance with VM-like isolation but still need to achieve desired technical maturity (in terms of microprocessor stability, process containment, persistent storage, etc.). VMs, on the other hand, are found to provide stable performance throughout, though bigger memory footprints and slower spin up/down remain their biggest weaknesses.},
	language = {en},
	urldate = {2024-06-09},
	journal = {IEEE Access},
	author = {Watada, Junzo and Roy, Arunava and Kadikar, Ruturaj and Pham, Hoang and Xu, Bing},
	year = {2019},
	keywords = {md2025},
	pages = {152443--152472},
	file = {Watada et al. - 2019 - Emerging Trends, Techniques and Open Issues of Con.pdf:/home/adam/Zotero/storage/BI2K78K5/Watada et al. - 2019 - Emerging Trends, Techniques and Open Issues of Con.pdf:application/pdf},
}

@misc{kubernetes_authors_horizontal_2024,
	title = {Horizontal {Pod} {Autoscaling}},
	url = {https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/},
	abstract = {In Kubernetes, a HorizontalPodAutoscaler automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of automatically scaling the workload to match demand.
Horizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.},
	language = {en},
	urldate = {2024-06-09},
	author = {Kubernetes Authors},
	month = feb,
	year = {2024},
	note = {Section: docs},
	file = {Snapshot:/home/adam/Zotero/storage/BD9LJQ8S/horizontal-pod-autoscale.html:text/html},
}

@article{lorido-botran_review_2014,
	title = {A {Review} of {Auto}-scaling {Techniques} for {Elastic} {Applications} in {Cloud} {Environments}},
	volume = {12},
	issn = {1572-9184},
	url = {https://doi.org/10.1007/s10723-014-9314-7},
	doi = {10.1007/s10723-014-9314-7},
	abstract = {Cloud computing environments allow customers to dynamically scale their applications. The key problem is how to lease the right amount of resources, on a pay-as-you-go basis. Application re-dimensioning can be implemented effortlessly, adapting the resources assigned to the application to the incoming user demand. However, the identification of the right amount of resources to lease in order to meet the required Service Level Agreement, while keeping the overall cost low, is not an easy task. Many techniques have been proposed for automating application scaling. We propose a classification of these techniques into five main categories: static threshold-based rules, control theory, reinforcement learning, queuing theory and time series analysis. Then we use this classification to carry out a literature review of proposals for auto-scaling in the cloud.},
	language = {en},
	number = {4},
	urldate = {2024-06-11},
	journal = {Journal of Grid Computing},
	author = {Lorido-Botran, Tania and Miguel-Alonso, Jose and Lozano, Jose A.},
	month = dec,
	year = {2014},
	keywords = {Auto-scaling, Cloud computing, Scalable applications, Service level agreement, md2025},
	pages = {559--592},
	file = {Full Text PDF:/home/adam/Zotero/storage/TV4MNHLM/Lorido-Botran et al. - 2014 - A Review of Auto-scaling Techniques for Elastic Ap.pdf:application/pdf},
}

@article{yuan_time_2024,
	title = {A {Time} {Series}-{Based} {Approach} to {Elastic} {Kubernetes} {Scaling}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/13/2/285},
	doi = {10.3390/electronics13020285},
	abstract = {With the increasing popularity of cloud-native architectures and containerized applications, Kubernetes has become a critical platform for managing these applications. However, Kubernetes still faces challenges when it comes to resource management. Specifically, the platform cannot achieve timely scaling of the resources of applications when their workloads fluctuate, leading to insufficient resource allocation and potential service disruptions. To address this challenge, this study proposes a predictive auto-scaling Kubernetes Operator based on time series forecasting algorithms, aiming to dynamically adjust the number of running instances in the cluster to optimize resource management. In this study, the Holt–Winter forecasting method and the Gated Recurrent Unit (GRU) neural network, two robust time series forecasting algorithms, are employed and dynamically managed. To evaluate the effectiveness, we collected workload metrics from a deployed RESTful HTTP application, implemented predictive auto-scaling, and assessed the differences in service quality before and after the implementation. The experimental results demonstrate that the predictive auto-scaling component can accurately predict the future trend of the metrics and intelligently scale resources based on the prediction results, with a Mean Squared Error (MSE) of 0.00166. Compared to the deployment using a single algorithm, the cold start time is reduced by 1 h and 41 min, and the fluctuation in service quality is reduced by 83.3\%. This process effectively enhances the quality of service and offers a novel solution for resource management in Kubernetes clusters.},
	language = {en},
	number = {2},
	urldate = {2024-06-12},
	journal = {Electronics},
	author = {Yuan, Haibin and Liao, Shengchen},
	month = jan,
	year = {2024},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cloud computing, cloud native, Kubernetes, md2025, predictive scaling, time series forecasting},
	pages = {285},
	annote = {This looks like a really promising article. It appears to even define success metrics!},
	file = {Full Text PDF:/home/adam/Zotero/storage/A4DT97MS/Yuan e Liao - 2024 - A Time Series-Based Approach to Elastic Kubernetes.pdf:application/pdf},
}

@book{siemsen_6_nodate,
	title = {6 {Time} series components {\textbar} {Demand} {Forecasting} for {Executives} and {Professionals}},
	url = {https://dfep.netlify.app/sec-tsfeatures},
	abstract = {This book prepares you to learn more about forecasting, or to have intelligent conversations about forecasting with actual experts.},
	urldate = {2025-02-21},
	author = {Siemsen, Bahman Rostami-Tabar \& Enno, Stephan Kolassa},
	keywords = {md2025},
	file = {Snapshot:/home/adam/Zotero/storage/N89PGDNX/sec-tsfeatures.html:text/html},
}

@misc{noble_what_2024,
	title = {What are {ARIMA} {Models}? {\textbar} {IBM}},
	url = {https://www.ibm.com/think/topics/arima-model},
	urldate = {2025-03-02},
	author = {Noble, Joshua},
	month = may,
	year = {2024},
	keywords = {md2025},
	file = {What are ARIMA Models  IBM.pdf:/home/adam/Zotero/storage/DUPS99Z2/What are ARIMA Models  IBM.pdf:application/pdf},
}

@book{shumway_time_2017,
	address = {Cham},
	series = {Springer {Texts} in {Statistics}},
	title = {Time {Series} {Analysis} and {Its} {Applications}: {With} {R} {Examples}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-319-52451-1 978-3-319-52452-8},
	shorttitle = {Time {Series} {Analysis} and {Its} {Applications}},
	url = {https://link.springer.com/10.1007/978-3-319-52452-8},
	language = {en},
	urldate = {2025-03-27},
	publisher = {Springer International Publishing},
	author = {Shumway, Robert H. and Stoffer, David S.},
	year = {2017},
	doi = {10.1007/978-3-319-52452-8},
	keywords = {ARIMA models, categorical time series analysis, dynamic linear models, GARCH models, long memory series, Markov chain Monte Carlo integration method, md2025, multivariate spectral methods, nonlinear models, R package, resampling techniques, spectral analysis, state-space analysis, stochastic volatility, wavelets integration method},
}

@article{qu_auto-scaling_2018,
	title = {Auto-{Scaling} {Web} {Applications} in {Clouds}: {A} {Taxonomy} and {Survey}},
	volume = {51},
	issn = {0360-0300},
	shorttitle = {Auto-{Scaling} {Web} {Applications} in {Clouds}},
	url = {https://doi.org/10.1145/3148149},
	doi = {10.1145/3148149},
	abstract = {Web application providers have been migrating their applications to cloud data centers, attracted by the emerging cloud computing paradigm. One of the appealing features of the cloud is elasticity. It allows cloud users to acquire or release computing resources on demand, which enables web application providers to automatically scale the resources provisioned to their applications without human intervention under a dynamic workload to minimize resource cost while satisfying Quality of Service (QoS) requirements. In this article, we comprehensively analyze the challenges that remain in auto-scaling web applications in clouds and review the developments in this field. We present a taxonomy of auto-scalers according to the identified challenges and key properties. We analyze the surveyed works and map them to the taxonomy to identify the weaknesses in this field. Moreover, based on the analysis, we propose new future directions that can be explored in this area.},
	number = {4},
	urldate = {2025-03-29},
	journal = {ACM Comput. Surv.},
	author = {Qu, Chenhao and Calheiros, Rodrigo N. and Buyya, Rajkumar},
	month = jul,
	year = {2018},
	keywords = {md2025},
	pages = {73:1--73:33},
	file = {1609.09224v6.pdf:/home/adam/Zotero/storage/7EEVUMA4/1609.09224v6.pdf:application/pdf},
}

@inproceedings{pufek_analysis_2019,
	title = {Analysis of {Garbage} {Collection} {Algorithms} and {Memory} {Management} in {Java}},
	url = {https://ieeexplore.ieee.org/document/8756844},
	doi = {10.23919/MIPRO.2019.8756844},
	abstract = {Significant elements of the Java Virtual Machine (JVM), as a part of the Java Platform, Standard Edition (Java SE), crucial for automatic memory management are various Garbage Collection (GC) algorithms. Since implementation of the Java Development Kit (JDK) is continuously being improved, it is difficult to ignore several new Java Enhancement Proposals (JEPs) correlated to memory management in JVM. Several different garbage collectors are implemented in addition to the existing aged Serial, Parallel, and Concurrent Mark \& Sweep (CMS) GC algorithms, as well as newer Garbage-First (G1) GC. The major progress since JDK 10 is making Parallel Full GC for G1, as a default multi-threaded GC when performing collections on an entire heap. Redundant overheads could appear when GC algorithms perform garbage collection too frequently, or a too large amount of memory could be allocated when garbage is not collected regularly. The goal of new algorithms' features is optimizing the overall process of releasing space so that pause times do not affect applications' performances negatively. This paper explores several garbage collectors available in JDK 11 by using selected benchmarking applications of the DaCapo suite for comparison of the number of algorithms' iterations and the duration of the collection time.},
	urldate = {2025-06-19},
	booktitle = {2019 42nd {International} {Convention} on {Information} and {Communication} {Technology}, {Electronics} and {Microelectronics} ({MIPRO})},
	author = {Pufek, P. and Grgić, H. and Mihaljević, B.},
	month = may,
	year = {2019},
	note = {ISSN: 2623-8764},
	keywords = {Compaction, DaCapo suite, G1, Garbage Collection Algorithm, Garbage Collector, Garbage-First, Instruction sets, Java, Memory management, Memory Management, Metadata, Parallel Full GC for G1, Resource management, Virtual machining},
	pages = {1677--1682},
	file = {Full Text PDF:/home/adam/Zotero/storage/7IJCDB42/Pufek et al. - 2019 - Analysis of Garbage Collection Algorithms and Memo.pdf:application/pdf},
}

@article{preda_optimizing_2016,
	title = {Optimizing memory use in {Java} applications, garbage collectors},
	volume = {VI},
	issn = {2069-3230, 2069-3230},
	url = {http://www.dbjournal.ro/archive/22/22_4.pdf},
	abstract = {Java applications are diverse, depending by use case, exist application that use small amount of memory till application that use huge amount, tens or...},
	language = {en},
	number = {4},
	urldate = {2025-06-19},
	journal = {Database Systems Journal},
	author = {Preda, Ştefan},
	month = may,
	year = {2016},
	note = {Publisher: Bucharest University of Economic Studies},
	pages = {27--32},
	file = {22_4.pdf:/home/adam/Zotero/storage/6A5DDLE9/22_4.pdf:application/pdf},
}

@misc{luksa_kubernetes_nodate,
	title = {Kubernetes in {Action}},
	url = {https://www.manning.com/books/kubernetes-in-action},
	abstract = {Kubernetes in Action{\textless}/i{\textgreater} is a comprehensive guide to effectively developing and running applications in a Kubernetes environment. Before diving into Kubernetes, the book gives an overview of container technologies like Docker, including how to build containers, so that even readers who haven't used these technologies before can get up and running.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2025-06-20},
	journal = {Manning Publications},
	author = {Lukša, Marko},
	keywords = {md2025},
	file = {Snapshot:/home/adam/Zotero/storage/Q7IFGCCB/kubernetes-in-action.html:text/html},
}

@book{sullins_jmx_2002,
	address = {USA},
	title = {{JMX} in {Action}},
	isbn = {978-1-930110-56-4},
	abstract = {From the Publisher:Covering the Java Management Extensions specification, this guide teaches programmers how JMX can provide robust management and monitoring capabilities for Java and non-Java resources including hardware. Going beyond covering the API, real-life examples and useful code are demonstrated in detail. In addition to describing the JMX specification, it provides techniques for using and extending the functionality provided by a JMX system. More specifically, included are all types of Mbeans, resources for working with JMX agents, in-depth chapters covering the JMX agent services, and ways to combine JMX with other Java technologies. Also included are chapters on using JMX with Enterprise Java Beans (EJB) and the Java Message Service (JMS) and examples of JMX adapters that can be used in applications such as TCP adapters and JINI adapters. In addition, the book contains several utility classes that will make JMX application development easier and techniques for extending certain JMX services to provide additional functionality. Author Biography:  Benjamin G. Sullins  is a senior-level Java developer with experience in both server- and client-side Java. Currently, he works with JSP and XML to develop collaborative online applications. He lives in Dallas, Texas.  Mark B. Whipple  is a software developer who has worked extensively with networked applications, including monitoring applications utilizing SNMP and, more recently, JMX. He has participated on several standards bodies, including the IETF. He lives in Dallas, Texas.},
	publisher = {Manning Publications Co.},
	author = {Sullins, Benjamin G. and Whipple, Mark},
	month = sep,
	year = {2002},
	keywords = {md2025},
}

@book{dantas_autoscaling_2023,
	title = {Autoscaling {Preditivo} de {Microsserviços} usando {Kubernetes}, {Keda} e {Séries} {Temporais}},
	url = {https://repositorio.ufrn.br/items/de1ceaa0-63fd-4435-8b14-c2ecdfc521ff},
	urldate = {2025-06-22},
	author = {Dantas, Lucas Oliveir},
	year = {2023},
	keywords = {md2025},
	file = {Autoscaling Preditivo de Microsserviços usando Kub.pdf:/home/adam/Zotero/storage/CKPM6RI4/Autoscaling Preditivo de Microsserviços usando Kub.pdf:application/pdf;Autoscaling Preditivo de Microsserviços usando Kubernetes, Keda e Séries Temporais:/home/adam/Zotero/storage/6RYQP5GN/de1ceaa0-63fd-4435-8b14-c2ecdfc521ff.html:text/html},
}

@article{yuan_using_2020,
	title = {Using {An} {Attention}-{Based} {LSTM} {Encoder}–{Decoder} {Network} for {Near} {Real}-{Time} {Disturbance} {Detection}},
	volume = {13},
	issn = {2151-1535},
	url = {https://ieeexplore.ieee.org/document/9072638},
	doi = {10.1109/JSTARS.2020.2988324},
	abstract = {Accurate prediction of future observations based on past data is the key to near real-time disturbance detection using satellite image time series (SITS). To overcome the limitations of existing methods, we present an attention-based long-short-term memory (LSTM) encoder–decoder model in which the historical time series of a pixel is encoded with a bidirectional LSTM encoder while the future time series is produced by another LSTM decoder. An attention mechanism is integrated into the encoder–decoder model to align the input time series with the output time series and to dynamically choose the most relevant contextual information while forecasting. Based on the proposed model, we develop a framework for near real-time disturbance detection and verify its effectiveness in the case of burned area mapping. The prediction accuracy of the proposed model is evaluated using moderate resolution imaging spectroradiometer (MODIS) time series and compared with state-of-the-art models. Experimental results show that our model achieves the best results in terms of lower prediction error and higher model fitness. We also evaluate the disturbance detection ability of the proposed framework. The proposed approach improves the detection rate of disturbances while suppressing false alarms, and increases the temporal accuracy. We suggest that the proposed methods provide new tools for enhancing current early warning systems in real time.},
	urldate = {2025-07-09},
	journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	author = {Yuan, Yuan and Lin, Lei and Huo, Lian-Zhi and Kong, Yun-Long and Zhou, Zeng-Guang and Wu, Bin and Jia, Yan},
	year = {2020},
	keywords = {Attention mechanism, encoder–decoder, Forecasting, Hidden Markov models, long-short-term memory (LSTM), md2025, near real-time disturbance detection, Predictive models, Real-time systems, Remote sensing, satellite image time series (SITS), Satellites, Time series analysis},
	pages = {1819--1832},
	file = {PDF:/home/adam/Zotero/storage/PRVN6TAK/Yuan et al. - 2020 - Using An Attention-Based LSTM Encoder–Decoder Network for Near Real-Time Disturbance Detection.pdf:application/pdf},
}

@article{masdari_survey_2020,
	title = {A survey and classification of the workload forecasting methods in cloud computing},
	volume = {23},
	issn = {1386-7857, 1573-7543},
	url = {http://link.springer.com/10.1007/s10586-019-03010-3},
	doi = {10.1007/s10586-019-03010-3},
	abstract = {One of the key components of proactive resource management and auto-scaling in cloud computing is workload prediction. In order to increase cloud performance, reduce energy consumptions, meet the necessary quality of service (QoS) level, forecast the energy consumption of data centres (DCs), and increase the scalability of cloud service providers, accurate workload prediction is of utmost importance. But workload prediction in the context of cloud computing is a difficult problem, and there are several techniques combining machine learning, data mining, and mathematical methods to solve this problem. The workload prediction systems put out in the literature to enhance resource management in cloud DCs are thoroughly reviewed in this scheme. It initially delivers a taxonomy of the necessary information surrounding the workload prediction environment.},
	language = {en},
	number = {4},
	urldate = {2025-09-20},
	journal = {Cluster Computing},
	author = {Masdari, Mohammad and Khoshnevis, Afsane},
	month = dec,
	year = {2020},
	keywords = {md2025},
	pages = {2399--2424},
	file = {PDF:/home/adam/Zotero/storage/JU6D86PU/Masdari e Khoshnevis - 2020 - A survey and classification of the workload forecasting methods in cloud computing.pdf:application/pdf},
}

@article{mulla_times_2024,
	title = {Times {Series} {Forecasting} of {Monthly} {Rainfall} using {Seasonal} {Auto} {Regressive} {Integrated} {Moving} {Average} with {EXogenous} {Variables} ({SARIMAX}) {Model}},
	volume = {38},
	issn = {1573-1650},
	url = {https://doi.org/10.1007/s11269-024-03756-5},
	doi = {10.1007/s11269-024-03756-5},
	abstract = {In this study, the monthly rainfall time series forecasting was investigated based on the effectiveness of the Seasonal Auto Regressive Integrated Moving Average with EXogenous variables (SARIMAX) model in the coastal area of Phaltan, taluka. Rainfall forecasting is so much helpful to crops and disaster planning and development during monsoon season. The performance of model was assessed using various statistical metrics such as coefficient of determination (R2), and root mean squared error (RMSE). In this study, we have used  multi-dimensional components as inputs in the SARIMAX model for prediction of monthly rainfall. In this work, we have tested two models such as first SARIMAX model orders are (1, 0, 1) and (0, 1, 0, 12), while the second model had orders of (1, 1, 1) and (1, 1, 1, 12). The results of two models have been compared and the performance of model show that the first model outperformed on the rainfall forecasting. The RMSE and R2 performance are 54.54 and 0.91 of first model, respectively, while the second model accuracy is RMSE of 71.12 and an R2 of 0.81. Hence best SARIMAX model has been used for forecasting of monthly time series rainfall from 2020 to 2025 for study area. The results of rainfall data analysis of climatic data are valuable for understanding the variations in global climate change.},
	language = {en},
	number = {6},
	urldate = {2025-10-10},
	journal = {Water Resources Management},
	author = {Mulla, Shahenaz and Pande, Chaitanya B. and Singh, Sudhir K.},
	month = apr,
	year = {2024},
	keywords = {AIC, PACF, Rainfall, SARIMAX model, Times series forecasting},
	pages = {1825--1846},
	file = {Full Text PDF:/home/adam/Zotero/storage/KQ95ZJJT/Mulla et al. - 2024 - Times Series Forecasting of Monthly Rainfall using Seasonal Auto Regressive Integrated Moving Averag.pdf:application/pdf},
}

@article{merkel_docker_2014,
	title = {Docker: {Lightweight} {Linux} {Containers} for {Consistent} {Development} and {Deployment}},
	volume = {241},
	url = {https://www.linuxjournal.com/content/docker-lightweight-linux-containers-consistent-development-and-deployment},
	abstract = {Take on “dependency hell” with Docker containers, the lightweight and nimble cousin of VMs. Learn how Docker makes applications portable and isolated by packaging them in containers based on LXC technology.},
	language = {en},
	number = {241},
	journal = {Linux Journal},
	author = {Merkel, Dirk},
	month = may,
	year = {2014},
	file = {Docker\: Lightweight Linux Containers for Consistent Development and Deployment | Linux Journal:/home/adam/Zotero/storage/QR4D2EB2/docker-lightweight-linux-containers-consistent-development-and-deployment.html:text/html;PDF:/home/adam/Zotero/storage/4I2TJUEI/Merkel - Docker Lightweight Linux Containers for Consistent Development and Deployment.pdf:application/pdf},
}

@article{moreau_containers_2023,
	title = {Containers for computational reproducibility},
	volume = {3},
	copyright = {2023 Springer Nature Limited},
	issn = {2662-8449},
	url = {https://www.nature.com/articles/s43586-023-00236-9},
	doi = {10.1038/s43586-023-00236-9},
	abstract = {The fast-paced development of computational tools has enabled tremendous scientific progress in recent years. However, this rapid surge of technological capability also comes at a cost, as it leads to an increase in the complexity of software environments and potential compatibility issues across systems. Advanced workflows in processing or analysis often require specific software versions and operating systems to run smoothly, and discrepancies across machines and researchers can impede reproducibility and efficient collaboration. As a result, scientific teams are increasingly relying on containers to implement robust, dependable research ecosystems. Originally popularized in software engineering, containers have become common in scientific projects, particularly in large collaborative efforts. In this Primer, we describe what containers are, how they work and the rationale for their use in scientific projects. We review state-of-the-art implementations in diverse contexts and fields, with examples in various scientific fields. Finally, we discuss the possibilities enabled by the widespread adoption of containerization, especially in the context of open and reproducible research, and propose recommendations to facilitate seamless implementation across platforms and domains, including within high-performance computing clusters such as those typically available at universities and research institutes.},
	language = {en},
	number = {1},
	urldate = {2025-10-18},
	journal = {Nature Reviews Methods Primers},
	author = {Moreau, David and Wiebels, Kristina and Boettiger, Carl},
	month = jul,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Software, Research management},
	pages = {50},
	file = {PDF:/home/adam/Zotero/storage/SY6WLLCI/Moreau et al. - 2023 - Containers for computational reproducibility.pdf:application/pdf},
}

@incollection{casalicchio_container_2019,
	address = {Cham},
	title = {Container {Orchestration}: {A} {Survey}},
	isbn = {978-3-319-92378-9},
	shorttitle = {Container {Orchestration}},
	url = {https://doi.org/10.1007/978-3-319-92378-9_14},
	abstract = {Container technologies are changing the way cloud platforms and distributed applications are architected and managed. Containers are used to run enterprise, scientific and big data applications, to architect IoT and edge/fog computing systems, and by cloud providers to internally manage their infrastructure and services. However, we are far away from the maturity stage and there are still many research challenges to be solved. One of them is container orchestration that makes it possible to define how to select, deploy, monitor, and dynamically control the configuration of multi-container packaged applications in the cloud. This paper surveys the state-of-the-art solutions and discusses research challenges in autonomic orchestration of containers. A reference architecture of an autonomic container orchestrator is also proposed.},
	language = {en},
	urldate = {2025-10-18},
	booktitle = {Systems {Modeling}: {Methodologies} and {Tools}},
	publisher = {Springer International Publishing},
	author = {Casalicchio, Emiliano},
	editor = {Puliafito, Antonio and Trivedi, Kishor S.},
	year = {2019},
	doi = {10.1007/978-3-319-92378-9_14},
	keywords = {Autonomous Container, Container Management, Container Orchestration, Container Technology, Container-based Systems},
	pages = {221--235},
	file = {PDF:/home/adam/Zotero/storage/PRS3SIRD/Casalicchio - 2019 - Container Orchestration A Survey.pdf:application/pdf},
}

@inproceedings{malviya_comparative_2022,
	title = {A {Comparative} {Analysis} of {Container} {Orchestration} {Tools} in {Cloud} {Computing}},
	url = {https://ieeexplore.ieee.org/abstract/document/9763171},
	doi = {10.23919/INDIACom54597.2022.9763171},
	abstract = {Cloud Computing is an emerging technology that is used not only by developers but also by end-users. It has vital importance in the Information Technology (IT) industries as its future would create a great transition from conventional IT services. These days, containerization in cloud computing has become an important research area. The selection of container orchestration tools is one of the difficult tasks for the organizations involved in the management of the vast number of containers. These tools have their strengths, weaknesses, and functionalities which need to be considered. This paper presents a comparative analysis of the container orchestration tools. This analysis would help the professionals to decide whether they need an orchestrator bound to a single technology or an orchestrator which provides the independent solution. In this paper, four popular orchestration tools viz., Kubernetes, Docker Swarm, Mesos, and Redhat OpenShift are analyzed on various parameters viz., security, deployment, stability, scalability, cluster installation, and learning curve. We observed that Kubernetes has the best scheduling features whereas Docker Swarm is easy to use. We also found that Mesos has good scalability whereas OpenShift is a highly secure orchestration tool.},
	urldate = {2025-10-18},
	booktitle = {2022 9th {International} {Conference} on {Computing} for {Sustainable} {Global} {Development} ({INDIACom})},
	author = {Malviya, Anshita and Dwivedi, Rajendra Kumar},
	month = mar,
	year = {2022},
	keywords = {Kubernetes, Cloud computing, Container, Job shop scheduling, Stability analysis, Scalability, Containers, Cloud Computing, Organizations, Container Orchestration, Apache Mesos, Docker Swarm, OpenShift, Processor scheduling},
	pages = {698--703},
	file = {Full Text PDF:/home/adam/Zotero/storage/W2PFAP9P/Malviya e Dwivedi - 2022 - A Comparative Analysis of Container Orchestration Tools in Cloud Computing.pdf:application/pdf},
}

@article{bruno_study_2019,
	title = {A {Study} on {Garbage} {Collection} {Algorithms} for {Big} {Data} {Environments}},
	volume = {51},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3156818},
	doi = {10.1145/3156818},
	abstract = {The need to process and store massive amounts of data—Big Data—is a reality. In areas such as scientific experiments, social networks management, credit card fraud detection, targeted advertisement, and financial analysis, massive amounts of information are generated and processed daily to extract valuable, summarized information. Due to its fast development cycle (i.e., less expensive to develop), mainly because of automatic memory management, and rich community resources, managed object-oriented programming languages (e.g., Java) are the first choice to develop Big Data platforms (e.g., Cassandra, Spark) on which such Big Data applications are executed.
            However, automatic memory management comes at a cost. This cost is introduced by the garbage collector, which is responsible for collecting objects that are no longer being used. Although current (classic) garbage collection algorithms may be applicable to small-scale applications, these algorithms are not appropriate for large-scale Big Data environments, as they do not scale in terms of throughput and pause times.
            In this work, current Big Data platforms and their memory profiles are studied to understand why classic algorithms (which are still the most commonly used) are not appropriate, and also to analyze recently proposed and relevant memory management algorithms, targeted to Big Data environments. The scalability of recent memory management algorithms is characterized in terms of throughput (improves the throughput of the application) and pause time (reduces the latency of the application) when compared to classic algorithms. The study is concluded by presenting a taxonomy of the described works and some open problems, with regard to Big Data memory management, that could be addressed in future works.},
	language = {en},
	number = {1},
	urldate = {2025-10-18},
	journal = {ACM Computing Surveys},
	author = {Bruno, Rodrigo and Ferreira, Paulo},
	month = jan,
	year = {2019},
	pages = {1--35},
	file = {PDF:/home/adam/Zotero/storage/B2ZCE7CN/Bruno e Ferreira - 2019 - A Study on Garbage Collection Algorithms for Big Data Environments.pdf:application/pdf},
}

@misc{gerring_java_2025,
	title = {Java on containers: a guide to efficient deployment},
	shorttitle = {Java on containers},
	url = {https://www.datadoghq.com/blog/java-on-containers/},
	abstract = {Learn how to tune the JVM, GC, and your containerized environment to efficiently deploy and manage Java applications in the cloud.},
	language = {en},
	urldate = {2025-10-18},
	journal = {Datadog},
	author = {Gerring, Scott, Nicholas Thomson},
	month = mar,
	year = {2025},
	file = {Snapshot:/home/adam/Zotero/storage/Q8L8VDVV/java-on-containers.html:text/html},
}

@article{lakshmikanthan_optimizing_2021,
	title = {Optimizing {Java} for {Containerized} {Environments}: {Docker} and {Kubernetes} {Best} {Practices}},
	volume = {2},
	issn = {3050-9416},
	shorttitle = {Optimizing {Java} for {Containerized} {Environments}},
	url = {https://ijaibdcms.org/index.php/ijaibdcms/article/view/70},
	doi = {10.63282/3050-9416.IJAIBDCMS-V2I4P104},
	abstract = {Containerization has done the magic where software deployment is concerned, as it has provided a mechanism through which applications can be easily packaged, distributed and managed. Docker and Kubernetes allow developers to package applications into lightweight standalone environments with all the necessary dependencies, thus guaranteeing applications work the same way in all environments. This is particularly important in large-scale systems, where scalability, reliability, and portability issues become essential in fulfilling the needs of today's organizational settings. But here, containerization brings some specific issues for Java applications. It is a classic example of enterprise-grade systems. These are as follows: Memory management and allocation, which appear poor, bigger start up time, and other related optimization problems which are found in every running Java application since Java and the JVM are resource hungry. The same factors may affect JVM running Java workloads more severely in limited resource settings such as containers, resulting in poor performance and high operational costs.
This paper examines ways through which Java applications can be tuned with the aim of enhancing the performance of containers at the minimum cost of resources. Some of them are JVM tuning, such as heap sizing and choosing the right garbage collectors, and auto scaling utilized by Kubernetes to optimize resources, such as container image size by modularity. This paper uses profiling tools, benchmarking processes, and experimental validation as part of a systematic method to analyze and solve these problems. Specific details reveal dramatic gains in system relevancy factors including, but not limited to, startup time, output rate, response time, and memory load. Targeted at developers and DevOps, who attempt tasking Java-based applications to modern cloud-native environments, the incoming work presents a response to challenges resulting from containerization. Moreover, best practices for future improvements, which include considering the usage of serverless deployment and other JVMs, like GraalVM, as the tendencies of modern deployment approaches' development are provided},
	language = {en},
	number = {4},
	urldate = {2025-10-18},
	journal = {International Journal of AI, BigData, Computational and Management Studies},
	author = {Lakshmikanthan, Govindarajan and Nair, Sreejith Sreekandan},
	month = dec,
	year = {2021},
	keywords = {Kubernetes, Docker, Resource Management, Containerization, Java, JVM Tuning},
	pages = {34--44},
	file = {Full Text PDF:/home/adam/Zotero/storage/BD3ZUAXY/Lakshmikanthan e Nair - 2021 - Optimizing Java for Containerized Environments Docker and Kubernetes Best Practices.pdf:application/pdf},
}

@article{nagaraj_parvatha_containerized_2021,
	title = {Containerized solutions for high performance java-based applications in {Kubernetes} ecosystems},
	volume = {2},
	issn = {25828185},
	url = {https://ijsra.net/node/7778},
	doi = {10.30574/ijsra.2021.2.1.0042},
	abstract = {While containerization and Kubernetes have made cloud-native application deployment almost ubiquitous, Java-based applications are faced with unique challenges when running in the containerized world. There is great scalability, portability, and resource efficiency powered by Kubernetes; however, Java’s memory management and garbage collection processes often make it a performance bottleneck. In this study, we investigate how to best optimize containerized Java-based applications in Kubernetes environments.},
	language = {en},
	number = {1},
	urldate = {2025-10-18},
	journal = {International Journal of Science and Research Archive},
	author = {{Nagaraj Parvatha}},
	month = apr,
	year = {2021},
	pages = {186--194},
	file = {PDF:/home/adam/Zotero/storage/XDHVUU4T/Nagaraj Parvatha - 2021 - Containerized solutions for high performance java-based applications in Kubernetes ecosystems.pdf:application/pdf},
}

@article{patricio_garbage_nodate,
	title = {Garbage {Collection} {Optimization} for {JVM} running {Big} {Data} {Workloads}},
	language = {en},
	author = {Patrício, Duarte},
	file = {PDF:/home/adam/Zotero/storage/ATGYNJUQ/Patrício - Garbage Collection Optimization for JVM running Big Data Workloads.pdf:application/pdf},
}

@misc{kubernetes_authors_resize_2025,
	title = {Resize {CPU} and {Memory} {Resources} assigned to {Containers}},
	url = {https://kubernetes.io/docs/tasks/configure-pod-container/resize-container-resources/},
	abstract = {FEATURE STATE: Kubernetes v1.33 [beta] (enabled by default: true) This page explains how to change the CPU and memory resource requests and limits assigned to a container without recreating the Pod.
Traditionally, changing a Pod's resource requirements necessitated deleting the existing Pod and creating a replacement, often managed by a workload controller. In-place Pod Resize allows changing the CPU/memory allocation of container(s) within a running Pod while potentially avoiding application disruption.},
	language = {en},
	urldate = {2025-10-19},
	journal = {Kubernetes},
	author = {Kubernetes Authors},
	month = sep,
	year = {2025},
	note = {Section: docs},
	file = {Snapshot:/home/adam/Zotero/storage/JKB88FQR/resize-container-resources.html:text/html},
}

@phdthesis{ferrer_juan_alisis_2025,
	title = {Análisis de la transformación tecnológica en {Liferay}},
	url = {https://riunet.upv.es/handle/10251/224243},
	abstract = {[ES] Liferay es una plataforma de experiencia digital (DXP) de código abierto líder en el desarrollo de portales web y gestión de contenido que ha experimentado una evolución significativa. Su transición de una arquitectura monolítica en Liferay 6.1 a una modular en Liferay DXP 7.3, gracias a OSGi, permite actualizaciones más flexibles y eficientes. Esta reconfiguración integral optimiza la gestión de contenido, mejorando estructuras y plantillas con compatibilidad para herramientas de diseño modernas y Bootstrap 4. Ha pasado de una arquitectura monolítica en Liferay 6.1 a una modular en Liferay DXP 7.3 gracias a OSGi, permitiendo actualizaciones más flexibles y eficientes sin afectar al resto del sistema. Este cambio va más allá de una simple actualización de software; representa una reconfiguración total de la plataforma, con mejoras en su arquitectura, metodología de desarrollo y experiencia del usuario. Además, Liferay DXP 7.3 optimiza la gestión de contenido, mejorando estructuras y plantillas con compatibilidad para herramientas de diseño actuales e incorporando Bootstrap 4 para una experiencia más moderna y accesible. En este trabajo, se ha implementado la migración de las plantillas y estructuras desde Liferay 6.1 a Liferay DXP 7.3, garantizando su correcta adaptación al nuevo sistema y validando su compatibilidad con las nuevas funcionalidades. Este proceso incluyó la actualización de los modelos de datos, la transformación de las plantillas a la nueva sintaxis y pruebas exhaustivas para asegurar su funcionamiento. El propósito de este trabajo es examinar las variaciones tecnológicas entre Liferay 6.1 y Liferay DXP 7.3, considerando sus repercusiones técnicas, beneficios y eventuales inconvenientes. Se analizarán también los métodos utilizados en la migración, incluyendo las soluciones aplicadas para las estructuras y plantillas, así como las recomendaciones útiles para enfrentar los posibles obstáculos durante este proceso. De esta forma, se pretende ofrecer una guía práctica que permita comprender y manejar la evolución de Liferay de manera eficiente y efectiva.},
	language = {Español},
	urldate = {2025-10-21},
	author = {Ferrer Juan, Abel},
	month = sep,
	year = {2025},
	file = {Full Text PDF:/home/adam/Zotero/storage/97SK5TUN/Ferrer Juan - 2025 - Análisis de la transformación tecnológica en Liferay.pdf:application/pdf},
}

@misc{koppula_liferay_2025,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Liferay: {A} {Comprehensive} {Study} on its {Architecture}, {Features}, and {Applications}},
	shorttitle = {Liferay},
	url = {https://papers.ssrn.com/abstract=5184574},
	doi = {10.2139/ssrn.5184574},
	abstract = {Liferay is an open-source enterprise portal that facilitates the creation of scalable and stable web applications, offering organizations a versatile platform for digital transformation. This paper discusses the architecture, main features, and uses of Liferay, with a focus on its application in enterprise content management, digital experience platforms, and workflow automation. It draws attention to the modular architecture, extensibility via plugins, and integration of Liferay with third-party systems like LDAP, SAML, and OAuth. In addition, the research considers the development of a portal via Liferay based on best practices, implementation methodology, case studies, and enterprise platform comparisons. The paper further explores the development challenges developers confront in adopting Liferay, which include customization complexities, performance finetuning, and security requirements. Lastly, it discusses the future horizon of Liferay in enterprise solutions, especially in domains like AI-powered personalization, cloud-native deployment, and microservices-based architectures.},
	language = {en},
	urldate = {2025-10-21},
	publisher = {Social Science Research Network},
	author = {Koppula, Sri Phani Deepthimai and Qureshi, Mujtaba Ashraf},
	month = mar,
	year = {2025},
	keywords = {API Integration, Cloud-native Deployment, Content Management System, Digital Experience Platform, Enterprise Portal, Liferay, Microser vices, Open-source, Portal Development, Role-based Access Control, Web Application Framework, Work-flow Automation},
	file = {PDF:/home/adam/Zotero/storage/XYZE8PL9/Koppula e Qureshi - 2025 - Liferay A Comprehensive Study on its Architecture, Features, and Applications.pdf:application/pdf},
}

@phdthesis{criollo_jimenez_desarrollo_2025,
	type = {{bachelorThesis}},
	title = {Desarrollo de una plataforma de experiencia digital ({DXP}) para modernizar los procesos de negocio y mejorar la entrega de servicios empresariales},
	url = {http://dspace.utpl.edu.ec/handle/29.500.19856/70874},
	abstract = {Abstract: This thesis presents the design, development and validation of a digital experience platform (DXP) hosted in the cloud with an omnichannel approach, aimed at optimizing business management and improving interaction with customers. This proposal arises in response to the need to modernize business processes by incorporating technological solutions that facilitate the adaptation of companies to the current digital environment.  The development of this curriculum integration work was structured in four main phases: analysis, architectural design, deployment and validation. These stages were carried out following international standards, guaranteeing a solid base for the implementation of scalable, secure and adaptable solutions to current business needs. The DXP prototype was evaluated through a case study, showing significant results, such as workflow optimization, a potential improvement in customer experience and the ability to adapt to complex business contexts. Overall, the proposed platform not only improves the operational management of the companies.},
	language = {spa},
	urldate = {2025-10-21},
	author = {Criollo Jiménez, José Adrián},
	year = {2025},
	note = {Accepted: 2025-03-18T13:37:43Z},
	file = {PDF:/home/adam/Zotero/storage/YFF75G7R/Cañar et al. - INGENIERO EN CIENCIAS DE LA COMPUTACIÓN.pdf:application/pdf;Snapshot:/home/adam/Zotero/storage/7HJIECZZ/70874.html:text/html},
}
