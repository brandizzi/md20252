It is evident from the results (Table \ref{tab:metrics_per_method_rounded}) that none of the models had a remarkable performance. $R^2$ was very low for all of them (none even got a positive result, thus being worse than just using the average value) and MAPE didn't even get below 20%.

MA and AR, alone, are especially por predictors. We have some extreme values, such as MAPE of over 99%. Maybe AR could get better results with other hyperparameters, but such poor performance tends to discourage this experimentation.

\begin{table}[h!]
\centering
\begin{tabular}{l l r r}
\toprule
\textbf{Method} & \textbf{Pod} & \textbf{R2} & \textbf{MAPE} \\ 
\midrule
\multirow{5}{*}{MA(2)} 
    & liferay-69cddb688-xkn4z & -14.05 & 99.98 \\ 
    & liferay-d75dd575-5snn6  & -8.49  & 99.97 \\ 
    & liferay-d75dd575-9ll42  & -8.59  & 99.99 \\ 
    & liferay-d75dd575-bkcxz  & -15.57 & 99.99 \\ 
    & liferay-d75dd575-zhg5p  & -7.50  & 99.98 \\ 
\midrule
\multirow{5}{*}{AR(4)} 
    & liferay-69cddb688-xkn4z & -13.59 & 97.85 \\ 
    & liferay-d75dd575-5snn6  & -8.19  & 97.58 \\ 
    & liferay-d75dd575-9ll42  & -8.39  & 98.20 \\ 
    & liferay-d75dd575-bkcxz  & -15.07 & 97.64 \\ 
    & liferay-d75dd575-zhg5p  & -7.30  & 97.49 \\ 
\midrule
\multirow{5}{*}{ARMA(4,2)} 
    & liferay-69cddb688-xkn4z & -0.10  & 23.51 \\ 
    & liferay-d75dd575-5snn6  & -1.09  & 35.44 \\ 
    & liferay-d75dd575-9ll42  & -0.44  & 28.97 \\ 
    & liferay-d75dd575-bkcxz  & -0.71  & 24.17 \\ 
    & liferay-d75dd575-zhg5p  & -3.26  & 57.53 \\ 
\midrule
\multirow{5}{*}{ARIMA(4,1,2)} 
    & liferay-69cddb688-xkn4z & 0.00   & 25.30 \\ 
    & liferay-d75dd575-5snn6  & 0.00   & 31.17 \\ 
    & liferay-d75dd575-9ll42  & 0.00   & 30.31 \\ 
    & liferay-d75dd575-bkcxz  & 0.00   & 22.55 \\ 
    & liferay-d75dd575-zhg5p  & -0.01  & 35.81 \\ 
\midrule
\multirow{5}{*}{SARIMA(4,1,2)(1,1,0)\_20} 
    & liferay-69cddb688-xkn4z & -1.24 & 39.81 \\ 
    & liferay-d75dd575-5snn6  & -0.51 & 42.47 \\ 
    & liferay-d75dd575-9ll42  & -0.54 & 44.14 \\ 
    & liferay-d75dd575-bkcxz  & -2.68 & 48.70 \\ 
    & liferay-d75dd575-zhg5p  & -0.32 & 45.13 \\ 
\bottomrule
\end{tabular}
\caption{R2 and MAPE metrics per pod for different forecasting methods (rounded to 2 decimal places)}
\label{tab:metrics_per_method_rounded}
\end{table}


The best results were clearly from ARMA and ARIMA. ARIMA even got a slightly worse performance when compared with MAPE, as can be more clearly seen in Figure \ref{fig:mape}. When compared by $R^2$, though, ARIMA fares slightly better, but not significantly so (Figure \ref{fig:r2}).

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{mape.png}
	\caption{Mean absolute percentage error for every model, per pod.}
	\label{fig:mape}
\end{figure}

SARIMA performed better than the most basic models, but worse than ARMA and ARIMA. This is not surprising, because the hyperparameters chosen for it were not, indeed, the ones one would prefer. It is a cautionary tale about using the proper hyperparameters: a more sophisticated model turned out worse for a poor choice. Sadly, better hyperparameters cannot be used with the current computational resoruces available. Nonetheless, the fact that SARIMA even got close to other models indicates it can be a proper model for the problem at hand.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{r2.png}
	\caption{$R^2$ every model, per pod.}
	\label{fig:r2}
\end{figure}