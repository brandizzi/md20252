\IEEEPARstart{A} solid understanding of Kubernetes is essential for the present study, as it provides the foundation for orchestrating containerized applications and managing resources efficiently. We rely primarily on \cite{luksa_kubernetes_nodate}, which offers a practical, in-depth exploration of Kubernetes architecture, deployment strategies, and operational patterns. This work is complemented by \cite{kubernetes_authors_horizontal_2024}, which emphasizes horizontal scaling strategies and best practices in cloud-native environments, providing a more recent perspective on Kubernetesâ€™ evolving ecosystem.

To account for Java Virtual Machine (JVM) behavior, \cite{sullins_jmx_2002} serves as our principal reference, particularly regarding internal metrics accessible via Java Management Extensions (JMX) and the operation of the garbage collector. Despite its age, this reference remains relevant due to the stability of JVM internal mechanisms and its detailed guidance on monitoring and interpreting runtime metrics. Understanding these metrics is crucial for predicting application performance and resource utilization, particularly when integrated with auto-scaling mechanisms.

A cornerstone of our research is the survey by \cite{lorido-botran_review_2014}, which provides a comprehensive overview of auto-scaling techniques, including both rule-based and model-driven approaches. Although older, its systematic classification of strategies remains influential. More recent surveys, such as \cite{masdari_survey_2020} and \cite{qu_auto-scaling_2018}, expand on this foundation by incorporating modern cloud-native practices, the role of machine learning, and updated evaluation criteria for scaling policies, highlighting the continuing evolution of the field.

While our broader goal encompasses multiple auto-scaling approaches, this study focuses specifically on time series-based methods for predicting resource demand. Introductory works like \cite{shumway_time_2017} and \cite{siemsen_6_nodate} provided foundational knowledge on time series analysis, including decomposition, smoothing, and forecasting techniques. Applied studies, including \cite{yuan_using_2020} and \cite{watada_emerging_2019}, demonstrated the potential of these methods for performance prediction and resource optimization in distributed systems. Moreover, recent work targeting Kubernetes environments, such as \cite{yuan_time_2024} and \cite{dantas_autoscaling_2023}, offers practical insights into metric collection, prediction accuracy, and implementation challenges, although their applicability to our specific objectives requires further assessment.

For this project, we explored a wide spectrum of time series analysis techniques, ultimately converging on the Seasonal Autoregressive Integrated Moving Average with Exogenous Regressors (SARIMAX) model. SARIMAX provides a generalized framework that incorporates autoregressive, moving average, and seasonal components while allowing the inclusion of exogenous variables, making it a flexible and robust approach for forecasting JVM memory usage in Kubernetes pods. The paper by \cite{mulla_times_2024} served as a key reference, highlighting both theoretical foundations and practical considerations. Its applicability is further reinforced by the widespread support for SARIMAX in contemporary statistical software, enabling reproducible and scalable analyses across diverse cloud-native workloads.